{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a18b3066-c33e-46df-84ba-804193abb382",
   "metadata": {},
   "source": [
    "# 利用分类标签比对的方法间接实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e841ac2-5d4e-4ddd-8a13-50549504adf2",
   "metadata": {},
   "source": [
    "## 用预训练模型辅助标注（先使用这个）\n",
    "实现方法：\n",
    "使用目标检测模型（如 YOLO、Faster R-CNN）对图片进行初步检测和分类。\n",
    "自动生成的标签再由人工快速校验和修改。\\\n",
    "工具：\n",
    "使用 百度飞桨（PaddleDetection） 或 PyTorch Hub 提供的目标检测模型。\n",
    "使用 TensorFlow Object Detection API 提供的预训练模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73825997-fbdd-413d-a46c-e6b3c057af7c",
   "metadata": {},
   "source": [
    "实现思路\n",
    "使用 YOLO 检测图像中的物体\n",
    "\n",
    "YOLO 的目标是检测图像中的目标，并生成：\n",
    "物体类别标签：如 \"car\"（汽车）、\"dog\"（狗）。\n",
    "检测框（Bounding Boxes）：标出目标的位置。\n",
    "置信度：预测结果的可信度。\n",
    "为每张图像生成一个标签集合\n",
    "\n",
    "将 YOLO 检测出的所有目标类别汇总，形成一个标签集合，例如：\n",
    "图像 A：[\"car\", \"person\", \"dog\"]\n",
    "图像 B：[\"cat\", \"tree\", \"person\"]\n",
    "构建一个图像数据库\n",
    "\n",
    "对于需要检索的图像库，使用 YOLO 检测每张图像并存储结果：\n",
    "图像路径。\n",
    "物体标签集合。\n",
    "（可选）目标的具体位置信息（检测框）。\n",
    "检索流程\n",
    "\n",
    "输入一张待检索的查询图像：\n",
    "用 YOLO 检测图像，生成该图像的标签集合（如 [\"car\", \"tree\"]）。\n",
    "与数据库中的标签集合进行比对，计算标签相似度（例如交集的大小）。\n",
    "返回标签最相似的图像作为检索结果。\n",
    "展示匹配结果\n",
    "\n",
    "对检索出的图像，根据相似度排序，展示匹配图像及其检测到的目标（包括检测框）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c6b1b1-454c-445f-a53f-a803c349cbe8",
   "metadata": {},
   "source": [
    "思路扩展\n",
    "目标检测框的定义\n",
    "\n",
    "每个检测目标由以下数据定义：\n",
    "标签：目标类别名称（如 \"car\"、\"person\"）。\n",
    "检测框：(x_min, y_min, x_max, y_max)，表示目标在图像中的位置。\n",
    "置信度：目标预测的可信度。\n",
    "位置信息的匹配方式\n",
    "\n",
    "\n",
    "基于位置匹配可以采用如下算法：\n",
    "检测框的交集面积\n",
    "检测框的并集面积\n",
    "IoU= \n",
    "检测框的并集面积\n",
    "检测框的交集面积\n",
    "​\n",
    " \n",
    "距离衡量：计算检测框中心点之间的欧几里得距离。\n",
    "权重综合：结合标签相似度和位置信息计算综合匹配得分。\n",
    "匹配结果排序\n",
    "\n",
    "使用目标标签匹配作为第一层过滤条件。\n",
    "在候选图像中，计算所有匹配目标的位置信息相似度（如 IoU）。\n",
    "综合匹配得分，按相似度排序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6095b378-22c3-4c5f-966a-3c06122c4889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\10843/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-1-7 Python-3.11.5 torch-2.5.1+cu121 CUDA:0 (Quadro T2000, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'person', 'bbox': [849.5234985351562, 2141.595703125, 3496.396484375, 5736.5302734375], 'confidence': 0.8936266899108887}, {'label': 'car', 'bbox': [0.0, 3454.009521484375, 1238.6787109375, 5760.0], 'confidence': 0.47308674454689026}, {'label': 'person', 'bbox': [1.1253690719604492, 3883.7490234375, 417.5061950683594, 4509.42578125], 'confidence': 0.318872332572937}]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 加载 YOLO 模型\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True).to(device)\n",
    "\n",
    "# 检测图像中的目标\n",
    "def detect_objects(image_path):\n",
    "    #print(image_path)\n",
    "    results = model(image_path)\n",
    "    objects = []\n",
    "    for _, row in results.pandas().xyxy[0].iterrows():\n",
    "        objects.append({\n",
    "            \"label\": row['name'],  # 目标类别\n",
    "            \"bbox\": [row['xmin'], row['ymin'], row['xmax'], row['ymax']],  # 检测框\n",
    "            \"confidence\": row['confidence']  # 置信度\n",
    "        })\n",
    "    return objects\n",
    "\n",
    "# 示例\n",
    "query_image = \"D:\\picture\\Training\\query.jpg\"\n",
    "query_image_labels = detect_objects(query_image)\n",
    "print(query_image_labels) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db0e979f-1aa2-4ad6-884e-a767146b1878",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "\n",
    "# 构建数据库\n",
    "def build_database(image_folder):\n",
    "    database = {}\n",
    "    image_paths = glob.glob(f\"{image_folder}/*.jpg\")\n",
    "    for image_path in image_paths:\n",
    "        objects = detect_objects(image_path)\n",
    "        database[image_path] = objects\n",
    "    return database\n",
    "\n",
    "# 保存为 JSON 文件\n",
    "database = build_database(\"D:\\picture\\Training\")\n",
    "with open(\"database.json\", \"w\") as f:\n",
    "    json.dump(database, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cec90695-9bf4-4a51-8440-31132ce9be95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 计算 IoU\n",
    "def calculate_iou(box1, box2):\n",
    "    x1 = max(box1[0], box2[0])\n",
    "    y1 = max(box1[1], box2[1])\n",
    "    x2 = min(box1[2], box2[2])\n",
    "    y2 = min(box1[3], box2[3])\n",
    "    \n",
    "    # 计算交集面积\n",
    "    inter_area = max(0, x2 - x1) * max(0, y2 - y1)\n",
    "    \n",
    "    # 计算并集面积\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "    union_area = box1_area + box2_area - inter_area\n",
    "    \n",
    "    # 避免除零错误\n",
    "    if union_area == 0:\n",
    "        return 0\n",
    "    \n",
    "    # 返回 IoU\n",
    "    return inter_area / union_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc5fc061-3b7c-4b65-ba09-d1871253fba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\picture\\Training\\query.jpg\n",
      "[('D:\\\\picture\\\\Training\\\\query.jpg', 3.0), ('D:\\\\picture\\\\Training\\\\IMG_6996.jpg', 0.7849665607487122), ('D:\\\\picture\\\\Training\\\\IMG_7018.jpg', 0.7726230583620426), ('D:\\\\picture\\\\Training\\\\IMG_7003.jpg', 0.7667829634435253), ('D:\\\\picture\\\\Training\\\\IMG_7015.jpg', 0.7517026128345199), ('D:\\\\picture\\\\Training\\\\IMG_7002.jpg', 0.6971159001375453), ('D:\\\\picture\\\\Training\\\\IMG_6984.jpg', 0.6633382202988782), ('D:\\\\picture\\\\Training\\\\IMG_7014.jpg', 0.6105143000587029), ('D:\\\\picture\\\\Training\\\\IMG_7012.jpg', 0.5381953096382172), ('D:\\\\picture\\\\Training\\\\IMG_6979.jpg', 0.32341043006191067), ('D:\\\\picture\\\\Training\\\\2023_03_15_17_42_IMG_1774.JPG', 0.003924756366049111), ('D:\\\\picture\\\\Training\\\\2023_03_15_17_42_IMG_1837.JPG', 0.0030302620355680296), ('D:\\\\picture\\\\Training\\\\2023_03_15_17_41_IMG_1772.JPG', 0.0), ('D:\\\\picture\\\\Training\\\\car.jpg', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# 加载数据库\n",
    "with open(\"database.json\", \"r\") as f:\n",
    "    database = json.load(f)\n",
    "\n",
    "#综合匹配度计算\n",
    "def match_images(query_objects, database):\n",
    "    results = []\n",
    "    \n",
    "    for image_path, db_objects in database.items():\n",
    "        total_similarity = 0\n",
    "        for q_obj in query_objects:\n",
    "            for db_obj in db_objects:\n",
    "                if q_obj['label'] == db_obj['label']:  # 标签匹配\n",
    "                    iou = calculate_iou(q_obj['bbox'], db_obj['bbox'])\n",
    "                    total_similarity += iou  # 加入 IoU 相似度\n",
    "        results.append((image_path, total_similarity))\n",
    "    \n",
    "    # 按相似度排序\n",
    "    results = sorted(results, key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "# 查询\n",
    "query_objects = detect_objects(\"D:\\picture\\Training\\query.jpg\")\n",
    "matches = match_images(query_objects, database)\n",
    "#matches = search_image(query_labels, database)\n",
    "print(matches)  # 返回匹配结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c5bba83-28c6-4e60-956b-653d62d99e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Image and Detected Objects:\n",
      "\n",
      "Top Matches:\n",
      "Matched Image: D:\\picture\\Training\\query.jpg, Similarity: 3.00\n",
      "Matched Image: D:\\picture\\Training\\IMG_6996.jpg, Similarity: 0.78\n",
      "Matched Image: D:\\picture\\Training\\IMG_7018.jpg, Similarity: 0.77\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "query_image = \"D:\\picture\\Training\\query.jpg\"\n",
    "def display_image_with_boxes(image_path, objects):\n",
    "    image = Image.open(image_path)\n",
    "    fig, ax = plt.subplots(1, figsize=(12, 8))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    # 绘制检测框\n",
    "    for obj in objects:\n",
    "        bbox = obj['bbox']\n",
    "        rect = patches.Rectangle(\n",
    "            (bbox[0], bbox[1]), bbox[2] - bbox[0], bbox[3] - bbox[1],\n",
    "            linewidth=2, edgecolor='r', facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "        ax.text(bbox[0], bbox[1] - 10, f\"{obj['label']} ({obj['confidence']:.2f})\", \n",
    "                color='red', fontsize=12, backgroundcolor=\"white\")\n",
    "    plt.show()\n",
    "print(\"Query Image and Detected Objects:\")\n",
    "display_image_with_boxes(query_image, query_objects)\n",
    "print(\"\\nTop Matches:\")\n",
    "for match in matches[:3]:  # 只展示前 3 个匹配结果\n",
    "    image_path, similarity = match\n",
    "    print(f\"Matched Image: {image_path}, Similarity: {similarity:.2f}\")\n",
    "    display_image_with_boxes(image_path, database[image_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3a041d-09a0-44ab-bf58-90d89119d5f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 使用标注好的数据集来自己训练（可实现性不大）\n",
    "适用场景：\n",
    "如果数据集中有公开的高质量分类标签，可以直接使用。\n",
    "常用数据集：\n",
    "ImageNet：分类标签数据集，覆盖 1000 多种类别。\n",
    "COCO Dataset：含目标检测和分类的多标签数据。\n",
    "Open Images Dataset：包含大量多标签标注图像，支持目标检测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf79234-fdc0-420d-878f-f39577fc0e1d",
   "metadata": {},
   "source": [
    "# 利用图像特征提取的方法直接实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c018c8d-0807-4d3e-acdf-08a63cea3a83",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 利用欧几里得距离（基本原理）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddac4e6-7c60-43e4-9f9a-151e3a03c7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 提取颜色直方图特征\n",
    "def extract_features(image, bins=(8, 8, 8)):\n",
    "    # 将图像转换为 HSV 颜色空间\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    # 计算颜色直方图\n",
    "    hist = cv2.calcHist([hsv_image], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n",
    "    # 归一化\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    return hist\n",
    "\n",
    "\n",
    "# 索引图像库\n",
    "def index_images(image_dir, bins=(8, 8, 8)):\n",
    "    index = {}\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is not None:\n",
    "            features = extract_features(image, bins)\n",
    "            index[image_name] = features\n",
    "    return index\n",
    "\n",
    "\n",
    "# 搜索与查询图像最相似的图像\n",
    "def search(query_features, index, top_k=10):\n",
    "    results = {}\n",
    "    for image_name, features in index.items():\n",
    "        distance = euclidean_distances([query_features], [features])[0][0]\n",
    "        results[image_name] = distance\n",
    "    # 按距离排序（越小越相似）\n",
    "    results = sorted(results.items(), key=lambda x: x[1])\n",
    "    return results[:top_k]\n",
    "\n",
    "\n",
    "# 显示结果\n",
    "def show_results(query_image_path, results, image_dir):\n",
    "    query_image = cv2.imread(query_image_path)\n",
    "    query_image = cv2.cvtColor(query_image, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, len(results) + 1, 1)\n",
    "    plt.imshow(query_image)\n",
    "    plt.title(\"Query Image\")\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    for i, (image_name, score) in enumerate(results, start=2):\n",
    "        result_image = cv2.imread(os.path.join(image_dir, image_name))\n",
    "        result_image = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)\n",
    "        plt.subplot(1, len(results) + 1, i)\n",
    "        plt.imshow(result_image)\n",
    "        plt.title(f\"Rank {i-1}\\nScore: {score:.2f}\")\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    # 图像库目录\n",
    "    image_dir = \"D:\\picture\\Training\"\n",
    "    # 查询图像路径\n",
    "    query_image_path = \"D:\\picture\\Training\\query.jpg\"\n",
    "    \n",
    "    # 索引图像库\n",
    "    print(\"Indexing images...\")\n",
    "    index = index_images(image_dir)\n",
    "    \n",
    "    # 读取查询图像并提取特征\n",
    "    query_image = cv2.imread(query_image_path)\n",
    "    query_features = extract_features(query_image)\n",
    "    \n",
    "    # 搜索最相似的图像\n",
    "    print(\"Searching for similar images...\")\n",
    "    results = search(query_features, index, top_k=20)\n",
    "    \n",
    "    # 显示结果\n",
    "    print(\"Displaying results...\")\n",
    "    show_results(query_image_path, results, image_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a5e532-a650-4b03-9d25-65f48850e6c2",
   "metadata": {},
   "source": [
    "## 使用预训练模型\n",
    "直接使用现成的深度学习模型（如 CNN）提取图像特征向量。\\\n",
    "适用模型：\\\n",
    "ResNet、VGG、EfficientNet：适合通用图像特征提取。\\\n",
    "CLIP (OpenAI)：结合文本和图像，适合更智能的匹配。\\\n",
    "百度飞桨 (PaddlePaddle)：中文支持更好，提供便捷的预训练模型调用。\\\n",
    "特征提取步骤：\\\n",
    "将输入图像传入模型，去掉最后的全连接层，只保留特征层输出。\\\n",
    "得到的特征向量是一个高维数组（如 512 或 2048 维），表示图像的特征信息。\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98cd47f9-0b11-41c1-a12b-bd16fe9ed53f",
   "metadata": {},
   "source": [
    "数据库的建立与管理\n",
    "存储图像特征：\n",
    "\n",
    "对图像库中的每张图片提取特征向量，存储到数据库中（如 NumPy 数组文件、SQLite、MongoDB）。\n",
    "同时保存图片的路径或文件名，便于后续检索时返回结果。\n",
    "高效检索工具：\n",
    "\n",
    "Annoy (Approximate Nearest Neighbors)：适合快速近似相似度搜索。\n",
    "FAISS (Facebook AI Similarity Search)：支持 GPU 加速的大规模特征检索库。\n",
    "3. 图像检索流程\n",
    "(1) 特征提取\n",
    "对用户上传的图像提取特征向量。\n",
    "(2) 相似度计算\n",
    "使用相似度度量方法比较查询图片的特征向量和数据库中的特征：\n",
    "欧几里得距离：适合衡量全局特征差异。\n",
    "余弦相似度：适合高维特征的匹配（值越接近 1，图像越相似）。\n",
    "(3) 结果排序\n",
    "根据相似度分数，对检索结果进行排序，返回最相似的几张图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140de8d3-a808-440b-816d-ae44dbc01d83",
   "metadata": {},
   "source": [
    "### 特征提取与特征存储"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea807456-fa8e-4e63-b4e9-5183bfd9268c",
   "metadata": {},
   "source": [
    "利用CNN从图像中提取特征。可以采用以下两种方法：\n",
    "\n",
    "预训练模型（Transfer Learning）：\n",
    "使用现成的预训练模型（如 ResNet、VGG、Inception 等）作为特征提取器。\n",
    "去掉最后一层分类器，提取中间层或倒数第二层的特征向量。\\\n",
    "自定义模型：\n",
    "构建自己的 CNN 模型，根据数据集训练，然后从中提取特征。\\\n",
    "示例代码（使用预训练 ResNet 提取特征）："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed006928-9332-4f65-99aa-bc8344b660bd",
   "metadata": {},
   "source": [
    "#### 对图片库进行特征提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9bd16-4e35-44c5-b3e5-0197c921c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 加载预训练模型用于特征提取\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # 移除分类层\n",
    "model.eval()\n",
    "\n",
    "# 图像预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 定义比对库路径\n",
    "image_dir = \"D:\\picture\\Training\"\n",
    "features_list = []  # 用于存储特征向量\n",
    "image_paths = []  # 用于存储图像路径\n",
    "\n",
    "# 遍历文件夹，提取每张图像的特征\n",
    "for img_file in os.listdir(image_dir):\n",
    "    img_path = os.path.join(image_dir, img_file)\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img).unsqueeze(0)  # 添加 batch 维度\n",
    "        \n",
    "    # 核心步骤：利用CNN提取特征\n",
    "    with torch.no_grad():\n",
    "        features = model(img_tensor).squeeze().numpy()\n",
    "        \n",
    "    features_list.append(features)\n",
    "    image_paths.append(img_path)\n",
    "\n",
    "# 将特征保存为 NumPy 数组\n",
    "features_array = np.array(features_list)\n",
    "np.save(\"database_features.npy\", features_array)\n",
    "np.save(\"database_paths.npy\", image_paths)  # 保存图像路径"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9caa9e2-fa7c-4bd8-b7d9-3fa8912297fd",
   "metadata": {},
   "source": [
    "#### 对查询图像进行提取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4295c3be-d842-494a-938a-a0ae2b9bf1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查询图像路径\n",
    "query_image_path = \"D:\\picture\\Training\\query.jpg\"\n",
    "# 加载并预处理查询图像\n",
    "query_img = Image.open(query_image_path).convert(\"RGB\")\n",
    "query_img_tensor = transform(query_img).unsqueeze(0)\n",
    "# 提取查询图像的特征\n",
    "with torch.no_grad():\n",
    "    query_features = model(query_img_tensor).squeeze().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2803690d-6288-4615-9b62-2b0398fc2e7f",
   "metadata": {},
   "source": [
    "### 相似度计算\n",
    "利用余弦相似度计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00296ad8-4c4f-4851-82f6-3f1093f5a710",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 加载比对库特征和路径\n",
    "database_features = np.load(\"database_features.npy\")\n",
    "database_paths = np.load(\"database_paths.npy\")\n",
    "\n",
    "# 计算相似度（使用余弦相似度）\n",
    "similarities = cosine_similarity(query_features.reshape(1, -1), database_features)\n",
    "\n",
    "# 获取最相似的前 K 张图像\n",
    "top_k = 5  # 返回前 5 张相似图像\n",
    "top_k_indices = similarities.argsort()[0][-top_k:][::-1]  # 按相似度降序排列\n",
    "\n",
    "# 显示结果\n",
    "for idx in top_k_indices:\n",
    "    similar_img_path = database_paths[idx]\n",
    "    print(f\"相似图像路径: {similar_img_path}, 相似度: {similarities[0, idx]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62165b6-4995-4fe7-8d4e-362e35d05d70",
   "metadata": {},
   "source": [
    "### 显示检索结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103e8b10-92c4-4165-9c5e-26a00e0cb06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 显示查询图像\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, top_k + 1, 1)\n",
    "plt.imshow(Image.open(query_image_path))\n",
    "plt.title(\"Query Image\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# 显示相似结果\n",
    "for i, idx in enumerate(top_k_indices, start=2):\n",
    "    similar_img_path = database_paths[idx]\n",
    "    plt.subplot(1, top_k + 1, i)\n",
    "    plt.imshow(Image.open(similar_img_path))\n",
    "    plt.title(f\"Rank {i-1}\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d945ef-7852-42d7-b753-1021507634d0",
   "metadata": {},
   "source": [
    "# UI封装"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe5263e-c07e-4f10-a959-932519658bc0",
   "metadata": {},
   "source": [
    "## 利用分类标签比对的方法\n",
    "运行方式\n",
    "保存代码为 app.py，在终端运行以下命令启动服务："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a81e84-94ea-4db2-a872-83823f1e9815",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import io\n",
    "# Streamlit UI\n",
    "st.title(\"基于 YOLO 的图像检索系统\")\n",
    "st.sidebar.header(\"功能选项\")\n",
    "\n",
    "# 上传查询图像\n",
    "query_image = st.sidebar.file_uploader(\"上传查询图片\", type=['jpg', 'png'])\n",
    "\n",
    "# 设置图像数据库路径\n",
    "image_folder = st.sidebar.text_input(\"数据库图片文件夹路径\", \"path_to_your_image_folder\")\n",
    "\n",
    "# 按钮：构建数据库\n",
    "if st.sidebar.button(\"构建数据库\"):\n",
    "    if image_folder:\n",
    "        st.sidebar.write(\"正在构建数据库，请稍候...\")\n",
    "        database = build_database(image_folder)\n",
    "        with open(\"database.json\", \"w\") as f:\n",
    "            json.dump(database, f)\n",
    "        st.sidebar.success(\"数据库已构建完成！\")\n",
    "    else:\n",
    "        st.sidebar.error(\"请指定有效的图片文件夹路径。\")\n",
    "\n",
    "# 加载数据库\n",
    "if st.sidebar.button(\"加载数据库\"):\n",
    "    try:\n",
    "        with open(\"database.json\", \"r\") as f:\n",
    "            database = json.load(f)\n",
    "        st.sidebar.success(\"数据库加载成功！\")\n",
    "    except FileNotFoundError:\n",
    "        st.sidebar.error(\"未找到数据库文件，请先构建数据库。\")\n",
    "\n",
    "# 检索并展示结果\n",
    "if query_image and st.sidebar.button(\"开始检索\"):\n",
    "    query_image_pil = Image.open(query_image)\n",
    "    query_image_path = \"query_image.jpg\"\n",
    "    query_image_pil.save(query_image_path)\n",
    "\n",
    "    # 检测查询图像目标\n",
    "    query_objects = detect_objects(query_image_path)\n",
    "    st.subheader(\"查询图像及检测结果\")\n",
    "    st.image(query_image_pil, caption=\"查询图像\", use_column_width=True)\n",
    "\n",
    "    # 检索相似图像\n",
    "    matches = match_images(query_objects, database)\n",
    "\n",
    "    # 显示检索结果\n",
    "    st.subheader(\"检索结果\")\n",
    "    for match in matches[:5]:  # 显示前 5 个匹配结果\n",
    "        matched_image_path, similarity = match\n",
    "        st.write(f\"匹配图像: {matched_image_path}, 相似度: {similarity:.2f}\")\n",
    "        buf = display_image_with_boxes(matched_image_path, database[matched_image_path])\n",
    "        st.image(buf, caption=f\"匹配结果: {matched_image_path}\", use_column_width=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4d9d96-1781-41e2-adb5-205be2eb2f5d",
   "metadata": {},
   "source": [
    "## 利用CNN提取图像特征的方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeeab251-1ef6-43e8-b1ae-90538dfb3319",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from PIL import Image\n",
    "from torchvision import models, transforms\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Streamlit 标题\n",
    "st.title(\"基于 CNN 的内容检索图像 (CBIR) 系统\")\n",
    "\n",
    "# 图像预处理和模型加载\n",
    "model = models.resnet50(pretrained=True)\n",
    "model = torch.nn.Sequential(*list(model.children())[:-1])  # 移除分类层\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 特征提取函数\n",
    "def extract_features(img_path_or_object):\n",
    "    if isinstance(img_path_or_object, str):\n",
    "        img = Image.open(img_path_or_object).convert(\"RGB\")\n",
    "    else:  # 如果是 Streamlit 上传的图像文件\n",
    "        img = Image.open(img_path_or_object).convert(\"RGB\")\n",
    "    img_tensor = transform(img).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        return model(img_tensor).squeeze().numpy()\n",
    "\n",
    "# 准备比对库特征\n",
    "@st.cache  # 缓存计算结果，提高速度\n",
    "def prepare_database(image_dir):\n",
    "    features, paths = [], []\n",
    "    for img_file in os.listdir(image_dir):\n",
    "        img_path = os.path.join(image_dir, img_file)\n",
    "        features.append(extract_features(img_path))\n",
    "        paths.append(img_path)\n",
    "    return np.array(features), np.array(paths)\n",
    "\n",
    "# 显示查询结果\n",
    "def display_results(query_path_or_object, top_k=5):\n",
    "    db_features, db_paths = prepare_database(image_dir)\n",
    "    query_features = extract_features(query_path_or_object)\n",
    "    \n",
    "    # 计算相似度\n",
    "    similarities = cosine_similarity(query_features.reshape(1, -1), db_features)\n",
    "    top_indices = similarities.argsort()[0][-top_k:][::-1]\n",
    "\n",
    "    # 显示查询图像\n",
    "    st.subheader(\"查询图像\")\n",
    "    if isinstance(query_path_or_object, str):\n",
    "        st.image(query_path_or_object, caption=\"查询图像\", use_column_width=True)\n",
    "    else:\n",
    "        st.image(query_path_or_object, caption=\"查询图像\", use_column_width=True)\n",
    "    \n",
    "    # 显示相似图像\n",
    "    st.subheader(\"最相似的图像\")\n",
    "    for rank, idx in enumerate(top_indices, start=1):\n",
    "        similar_img_path = db_paths[idx]\n",
    "        similarity_score = similarities[0, idx]\n",
    "        st.image(similar_img_path, caption=f\"Rank {rank} - 相似度: {similarity_score:.4f}\", use_column_width=True)\n",
    "\n",
    "# 比对库路径\n",
    "image_dir = \"image_database\"\n",
    "\n",
    "# Streamlit 主界面\n",
    "st.sidebar.header(\"操作选项\")\n",
    "uploaded_file = st.sidebar.file_uploader(\"上传查询图像\", type=[\"jpg\", \"jpeg\", \"png\"])\n",
    "\n",
    "if uploaded_file:\n",
    "    st.sidebar.success(\"图像上传成功！\")\n",
    "    if st.sidebar.button(\"开始检索\"):\n",
    "        display_results(uploaded_file)\n",
    "else:\n",
    "    st.info(\"请在左侧上传一张查询图像。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11873aa9-4e20-4717-b8eb-f214b2cd9dc3",
   "metadata": {},
   "source": [
    "## 两者结合起来的最终封装"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
